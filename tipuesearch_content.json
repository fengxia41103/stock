{"pages":[{"title":"Dev & Deployment","text":"Both the backend and the frontend have been dockerized. Thus, regardless your platform, install Docker & docker-compose first. For user Clone the repo . Go to the project root folder, docker-compose up --build -d . Create a backend admin user: docker-compose run web python manage.py createsuperuser , and follow the instructions. Email is optional. Go to browser http://localhost:8084 , and use the user account to login. Now you should be ready to use the application by adding stocks and sectors. For developers Modify code Using the docker way is preferred. Code will be mounted into the docker as volume (see docker-compose.yaml for details). Thus changes done on your local editor will be reflected in the running docker as live . Debugging It may sound 1980. But the most effective way is to use docker-compose logs -f <service name> to see stack trace and/or error messages. Testing Looking for volunteers !! For network admins networks Network of the setup is fairly simple. We distinguish data vs. management : Stock app networks ports I try to limit exposure of ports on docker host so this application can be easily co-hosted with others without causing port conflicts. In essence, 8084 is the frontend UI port, and 8003 is the backend API port. All others are docker-to-docker only. Component Docker Port Service Host Map Frontend 80 Main frontend app w/ Nginx built-in 8084 Backend 80 Nginx proxy 8003 Backend 3306 MySql DB none Backend 8001 Django app none Backend 6379 Redis none Port mapping can be changed in docker-compose.yml . For example, if to change the frontend proxy from 8084 to 9999 , change the line ports from 8084:80 to 9999:80 . See docker-compose doc for details. frontend : .... ports : - \"8084:80\" # <========= change this line! ....","tags":"misc","url":"https://fengxia41103.github.io/stock/dev%20and%20deployment.html"},{"title":"Stock App Design","text":"Backdrop The app is a complete rewrite of one which I wrote five years ago. At the time Jookun approached me that he had some wise strategies of investment. I was intrigued by his passion, but wanted to verify its worth using some simulation. Thus a Django was created with Yahoo finance daily data as the input, and some data crunch based on his idea. Like all other ideas, I started to come up some of my own while working on it, and gradually it let me deep down into the rabbit hole — for the first time in my career, I had computation so intense that it would overheat my laptop and had it shut down! I felt I was on track of something. However, it had then been left to rot since. Though I had tried to revive it over the years, some of the code was done in such a complex manner that I didn't have the heart to read it again. One impression, however, always left me with a hope, the difficulty of obtain these free daily data. As mentioned, I started with Yahoo data. However, it was shut down just around that time. Later I shifted to Alpha Advantage while it was still free of use. Well, not anymore. Soon after I switched to it, I guess it gained enough popularity that it went on with memberships and so on. What jumping through these hoops occurred to me that if I could just publish these historical data somehow, and let people download and use them, there are already value. So recently, I started to think about this idea. Starting with another round of reviving the old app, I implemented Django command to dump DB data into CSVs, thus creating 500+ files, each representing a SP500 symbol, which were what I had. However, I want more — how about a better user experience? how about some computation of probabilities based on a layman's observation? how about DCF?... all these, eventually propelled me to rewrite this from scratch, and here it is. Audience & goals First, it is an absolute illusion if a beginner like myself will beat the market by these analysis, not only because of limitation of knowledge, information, and experience, but of personality. I don't know what the winners are like. Internet is filled with articles on what it takes to be a good investor. I have some of those qualities, but there is no guarantee nonetheless. Therefore, I'm back to zero. But one thing I am certain, that everyone will experience what I have experienced, at some point of his/her life, that they are curious, or interested in, the stock market, have the itch to try, know some bits of it, but not a whole lot, and have some basic hunch of some pattern , or frequency , or occurance , and thought there might be a gold mine buried underneath and yourself might be the lucky one. So, how to find out, or to verify? Here are five levels of users I sense: Type Tool Audience 1 apps & websites Have basic knowledge, satisfied with reported info 2 Excel Think they have some data/info analysis edge 3 Excel + VBA Automate routine computation and data assembly 4 Script or lib Programmer who gained more computation power over Excel 5 Commercial Professional, sky is the limit, membership Difference between 3 & 4 are blurry, but the idea is that scripting/lib will give you a much wider selection of tools than VBA. Further, VBA is not as good a building block if you want to stand on the shoulder of a giant. Users of type 1 and type 5 are not my audience. User of type 2,3,4 are essentially the same people — they are independent/self-confident enough to think of their own method, but are yet willing to go with a commercial source or solution they have some financial knowledge, and are not afraid of (or even fond of) data crunching. Their routine follows these steps — Obtain raw data: daily price (well, you could also have finer grain data) financial reports: balance sheet, income statement, cash flow computed ratios, eg. P/E, beta some popular indicator or evaluation values Crunch of his own indicator or measure using these data Draw a graph here and there to visualize his results Search for pattern During my research and implementation, following this pattern, I found a few places where this tool can help: Getting data . represented the first barrier higher than expected. I have related my experience w/ Yahoo, Google, Alpha. I'm surprised how limited such data sources are there considering how widely spread the Internet has become, and stock data being always in the public domain. A value of this tool is to handle API of available data sources so to retrieve available raw data. Cleansing data . Once you get data, consuming data represents another barrier — understanding particular data form (← this is usually source dependent) and handling data anomaly. 2nd value of this tool is to normalize these data points, and potentially amending missing data by providing reasonable default. Computing standard ratios . Crunching a clean data set is usually not the challenge at all. Of course you can go with your fancy where the edge is believed to be. However, there are always a few standard ratios everyone seems to begin with, eg. growth rate of a number from period to period, or pcnt of one expanse of the total, things like that. They are not difficult to compute, but rather mechanical/tedious, and are not readily available from a data source 1 . Therefore, you have to do them manually . Therefore, 3rd value of this tool is to provide some computed values out of box. One beauty of historical data is that they don't change. Therefore, a pre-calculated result is as good as new. In short, one can view this tool as a fancy automated Excel template that I have built to facilitate routine works and get you going w/ your analysis quickly less the mechanical build-up that is necessary but distracting from analysis itself. System design Stock app high level design System is split into backend and fronend. Backend is a Django app w/ exposed REST API using Tastypie . Frontend is React . Primary data source is Yahoo's financial data. In particular, I'm pulling these: historical stock daily prices — high, low, open, close, volume financial statements — balance sheet, income statement, and cash flow statement published meta — beta, P/E, and so on. Since these are opinionated, Yahoo is just one of many alternatives. Data model Model names are intuitive. Name Description MyStock Place for name, symbol MyStockHistorical Daily trading data MyStrategyValue Pre-computed values based on historical, eg. moving average IncomeStatement As name BalanceSheet As name CashFlow As name ValuationRatio Published valuation ratios, eg. P/E. They are source dependent. Stock app data models Data persistence & processing Data persistence is MySql 5.7. Using Django's ORM, this is not a hard requirement if your preference is something else. Data processing is handled by Redis via Celery so to achieve ease of scale. As mentioned earlier, MyStrategeValue are derived from historicals, thus are computed prehand using this mechanism: Django custom command → compose celery task → submit task to Redis queue → task executed and data is persisted to DB. There are also custom model property which is computed on the fly. Most of them can be pre-computed also since historicals are not static. However, to minimize dependency on these values that must be prepared as a separate step, I opted to the current method. By observation, performance penalty by not having them in DB is acceptable. Using docker, the following data volumes are used: Volume Attach to stock-data Main DB data storage redis-data Redis data storage Develop & Deployment See dev & deployment for details. Some source provide indicators such as MACD. Most, however, only provide raw/reported data such as sales of an Income Statement. My goal, therefore, is to follow the conventional train of thought by converting these values into percentage, and some period-to-period change rate, and so on, which I found myself doing a lot whenever I receive an Excel full of numbers. ↩","tags":"misc","url":"https://fengxia41103.github.io/stock/stock%20app%20design.html"}]}